# Parallel null model using a SOCK cluster archictecture
# Example used: functional diversity
# For this example we will compute functional richness (FRic) and functional divergence (FDiv)
# FRic measures the volume of the convex hull in the functional space occupied by a set of species from a given community
# FDiv measures measures how species are distributed within the volume filled by the assemblage (Mouillot
# et al. 2013a). FDiv measures the relative position of species from the gravity centre of the most extreme species (i.e. those
# at the edge of the convex hull). FDiv is close to 1 if most species are close to the border of the convex hull and is close to
# 0 if most species are close to the gravity centre of the volume filled by the assemblage.

# Reference: Vill√©ger, S., N. W. H. Mason and D. Mouillot (2008) New multidimensional functional diversity
# indices for a multifaceted framework in functional ecology. Ecology 89:2290-2301.

# Data: (1) Community data: Fish communities from France's reservoirs [83 communities and 45 species)
#       (2) Trait data: morphological and ecological traits (25 traits)

require(FD)
require(doSNOW)
require(picante)
require(ade4)

# load data
comm<-load(X)
traits<-load(X)

#

# compute observed values for functional diversity metrics (FRic and FDiv)
FD_results<-dbFD(traits, comm,  w.abun = FALSE, calc.FRic = TRUE, calc.FDiv = TRUE)

# FD compute a bunch of different metrics, but we only are interested in FRic and FDiv)
FD_obs <- as.data.frame(cbind(FRic = FD_results$FRic, FDiv = FD_results$FDiv)) 

# Now the null model

# define number of cores
nc <- 4 
    
# create cluster
cl <- snow::makeCluster(nc, type = "SOCK")
    
# register parallel backend 
doSNOW::registerDoSNOW(cl)
 
# export necessary variables and functions to the cluster of cores
snow::clusterExport(cl=cl, c("nperm", "comm", "traits","dbFD_modif"),envir=environment()) 
 
# define number of permutations for the null model
nperm <- 1000

# The ".combine" argument in the foreach loop specifiy how the user wants to combine the output of all cores together
# Because the final output of our function is a list object, we use the argument ".combine=c"
# to concatanate the list objects from each core into the "null_model_FD" object 
null_model_FD <- foreach(n=1:nc, .combine=c, .packages=c("picante","FD")) %dopar% {

# "nt" is the number of tasks per core (i.e., the number of permutations per core)
nt=nperm/nc

# replicate "nt" times the temporary result matrix where null "FRic" and "FDiv" results will be stored into a list object
  null_model_FD_temp <- replicate(nt,matrix(0, ncol=2, nrow=nrow(comm),dimnames = list(NULL,c("FRic","FDiv"))),simplify=FALSE)

# replicate "nt" times the commmunity matrix
  rep.comm<-replicate(nt,comm,simplify=FALSE)
# randomize the "nt" community matrices, keeping richness equal to observed
  rand.comm<-lapply(rep.comm, function(x) randomizeMatrix(x,null.model="richness",iterations=1000))
 for (j in 1:nt){
        
        # Compute FRic, FDIv for each randomized community matrix 
		# Here we used a modified version of the dbFD function that allows for parallelization by identifying each core "core.ident=n"		
          result_FD<-dbFD_modif(traits_pc,rand.comm[[j]],w.abun=F,calc.FRic = T, m=4,calc.FGR=F, calc.FDiv =T, core.ident=n)
		# store results 
          null_model_FD_temp[[j]]<-cbind(FRic = result_FD$FRic,FDiv=result_FD$FDiv)
        # print(length(which(is.na(result_FD$FDiv))))
      }
	  # it is necessary to indicate the core output here (null_model_FD_temp)  
	  # so the function will combine them at the end on the "null_model_FD" 
      null_model_FD_temp
    }

	# close the cluster
    stopCluster(cl)
 
  # create matrices to store mean and sd values of the metrics (FRic, FDiv) for each lake (mean/sd of the null values)
  FD_null_mean<-matrix(numeric(),ncol=2,nrow=nrow(comm))
  FD_null_sd<-matrix(numeric(),ncol=2,nrow=nrow(comm))
  colnames(FD_null_mean)<-c("FRic","FDiv")
  colnames(FD_null_sd)<-c("FRic","FDiv")
  
  # create a matrix to store p-values for each metric (FRic, FDiv)
  p<-matrix(numeric(),ncol=2,nrow=nrow(comm))
 
  # for each lake "i"
  for (i in 1:nrow(comm)){
    
    # extract the "nperm" values obtained from the null model
    null_values<-do.call(rbind,lapply(null_model_FD, `[`,i,))
    
    
    # compute mean and standard deviation of these null values
    FD_null_mean[i,]<-colMeans(null_values)
    FD_null_sd[i,]<-apply(null_values,2,sd)
    
    # compute p-values for each metric (i.e., the number of time the observed metric (FRic, FDiv) 
    # is smaller than the null value divided by nperm
    p[i,1]<-length(which(FD_obs[i,]<null_values[,1]))/nperm
    p[i,2]<-length(which(FD_obs[i,]<null_values[,2]))/nperm 
  }

  # compute standardizes effect sizes (SES) of both FRic and FDiv for each lake
    FD_ses<-(FD_obs-FD_null_mean)/FD_null_sd
  
  # combine everything into a result matrix
  res<-as.data.frame(matrix(numeric(),ncol=6,nrow=nrow(comm)))
  colnames(res)<-c("FRic.obs","FRic.ses","FRic.p","FDiv.obs","FDiv.ses","FDiv.p")
  res[,1]<-FD_obs[,1]
  res[,2]<-FD_ses[,1]
  res[,3]<-p[,1]
  res[,4]<-FD_obs[,2]
  res[,5]<-FD_ses[,2]
  res[,6]<-p[,2]
 
  
  
  
  
