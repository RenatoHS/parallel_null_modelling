#########################################################################################################################################
# Parallel null model using a SOCK cluster archictecture 
#########################################################################################################################################
# Example used: functional diversity
# For this example we will compute functional richness (FRic) and functional divergence (FDiv)
# FRic measures the volume of the convex hull in the functional space occupied by a set of species from a given community
# FDiv measures measures how species are distributed within the volume filled by the assemblage (Mouillot
# et al. 2013a). FDiv measures the relative position of species from the gravity centre of the most extreme species (i.e. those
# at the edge of the convex hull). FDiv is close to 1 if most species are close to the border of the convex hull and is close to
# 0 if most species are close to the gravity centre of the volume filled by the assemblage.
# Functional diversity metrics will be computed using a modified version of the dbFD function from the 'FD' package.

# References: 
# Villéger, S., N. W. H. Mason and D. Mouillot (2008) New multidimensional functional diversity
# indices for a multifaceted framework in functional ecology. Ecology, 89:2290-2301.

# Laliberté, E. and P. Legendre (2010) A distance-based framework for measuring functional diversity for multiple traits.
# Ecology, 91:299-305.

# SOCK Cluster can be used on Linux, Windows or OX. However, this script was only tested on Windows and Linux. 
#########################################################################################################################################
# Code written by Renato Henriques-Silva

# Copyright GPL-2 2012 Renato Henriques-Silva
# http://www.gnu.org/licenses/gpl-2.0.txt
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
############################################################################################################################################

# Data: (1) Community data: Fish communities from France's reservoirs [83 communities x 45 species]
#       (2) Trait data: morphological and ecological traits (45 species x 25 traits)

require(FD)
require(doSNOW)
require(picante)
require(ade4)

# load data
# community data
urlfile_comm <- 'https://raw.githubusercontent.com/RenatoHS/parallel_null_modelling/master/lake_comm.txt'
comm <- read.table(urlfile_comm, sep=";", head=TRUE)

# trait data
urlfile_traits <- 'https://raw.githubusercontent.com/RenatoHS/parallel_null_modelling/master/traits_fishlakes.txt'
traits<-read.table(urlfile_traits, sep=";", head=TRUE)

# traits have qualitate and quantitative data, plus some missing values. Transform the data using the Gower distance method
traits_gowdis <- FD::gowdis(traits)

# compute principal coordinate analysis (PCoA) on the gower distance values; keep first four axes 
traits_pc <- dudi.pco(traits_gowdis, scannf = FALSE, nf = 4)

# get principal coordinate scores
traits_pc <- traits_pc$li

# load dbFD_modif function. The original function was modified to allow for external paralelization. 
source("https://raw.githubusercontent.com/RenatoHS/parallel_null_modelling/master/dbFD_modif")

# compute observed values for functional diversity metrics (FRic and FDiv)
FD_results <- dbFD(traits_pc, comm,  w.abun = FALSE, calc.FRic = TRUE, calc.FDiv = TRUE)

# FD compute a bunch of different metrics, but we only are interested in FRic and FDiv)
FD_obs <- as.data.frame(cbind(FRic = FD_results$FRic, FDiv = FD_results$FDiv)) 

# Now the null model

# define number of cores --> verify the number of cores available with "parallel::detectCores()" (require parallel library)
nc <- 4 
    
# create cluster
cl <- snow::makeCluster(nc, type = "SOCK")
    
# register parallel backend 
doSNOW::registerDoSNOW(cl)
 
 # define number of permutations for the null model
nperm <- 1000

# make sure that nperm/nc is a whole number so that all cores have the same number of permutations to work on
# in this example, we use 1000 permutations divided by 4 cores, hence 250 permutation per core

# export necessary variables and functions to the cluster of cores
snow::clusterExport(cl = cl, c("nperm", "comm", "traits","dbFD_modif"),envir=environment()) 
 
# The ".combine" argument in the foreach loop specifiy how the user wants to combine the output of all cores together
# Because the final output of our function is a list object, we use the argument ".combine=c"
# to concatanate the list objects from each core into the final "null_model_FD" object 
null_model_FD <- foreach(n = 1:nc, .combine=c, .packages = c("picante","FD")) %dopar% {

# "nt" is the number of tasks per core (i.e., the number of permutations per core)
nt <- nperm/nc

# replicate "nt" times the temporary result matrix where null "FRic" and "FDiv" results will be stored into a list object
  null_model_FD_temp <- replicate(nt,matrix(0, ncol=2, nrow=nrow(comm),dimnames = list(NULL,c("FRic","FDiv"))),simplify=FALSE)

# replicate "nt" times the commmunity matrix
  rep.comm <- replicate(nt, comm, simplify=FALSE)
  
# randomize all "nt" community matrices, keeping richness equal to observed (users may adapt the null model algorithm to its needs)
  rand.comm <- lapply(rep.comm, function(x) randomizeMatrix(x, null.model="richness", iterations=1000))
 for (j in 1:nt){
        
        # Compute FRic, FDIv for each randomized community matrix 
        # Here we used a modified version of the dbFD function that allows for parallelization by identifying each core "core.ident=n"		
          result_FD <- dbFD_modif(traits_pc, rand.comm[[j]], w.abun=F, calc.FRic = T, m=4, calc.FGR=F, calc.FDiv =T, core.ident=n)
        
	# store results 
          null_model_FD_temp[[j]] <- cbind(FRic = result_FD$FRic, FDiv=result_FD$FDiv)
      }
	# it is necessary to indicate the core output here (null_model_FD_temp)  
	# so the function will combine them at the end on the "null_model_FD" 
        null_model_FD_temp
    }

  # close the cluster
  stopCluster(cl)
 
  # create matrices to store mean and sd values of the metrics (FRic, FDiv) for each lake (mean/sd of the null values)
  FD_null_mean <- matrix(numeric(), ncol=2, nrow=nrow(comm), dimnames=list(row.names(comm), c("FRic","FDiv")))
  FD_null_sd <- matrix(numeric(), ncol=2, nrow=nrow(comm), dimnames=list(row.names(comm), c("FRic","FDiv")))

  
  # create a matrix to store p-values for each metric (FRic, FDiv)
  p <- matrix(numeric(), ncol=2, nrow=nrow(comm))
 
  # for each lake "i"
  for (i in 1:nrow(comm)){
    
    # extract the "nperm" values obtained from the null model
    null_values <- do.call(rbind, lapply(null_model_FD, `[`,i,))
    
    
    # compute mean and standard deviation of these null values
    FD_null_mean[i,] <- colMeans(null_values)
    FD_null_sd[i,] <- apply(null_values, 2, sd)
    
    # compute p-values for each metric (i.e., the number of time the observed metric (FRic, FDiv) 
    # is smaller than the null value divided by nperm
    p[i,1] <- length(which(FD_obs[i,1] < null_values[,1]))/nperm
    p[i,2] <- length(which(FD_obs[i,2] < null_values[,2]))/nperm 
  }

  # compute standardizes effect sizes (SES) of both FRic and FDiv for each lake
    FD_ses <- (FD_obs-FD_null_mean)/FD_null_sd
  
  # combine everything into a result matrix
  res <- as.data.frame(matrix(numeric(), ncol=6, nrow=nrow(comm),dimnames=list(row.names(comm),
  c("FRic.obs","FRic.ses","FRic.p","FDiv.obs","FDiv.ses","FDiv.p"))))

  res[,1] <- FD_obs[,1]
  res[,2] <- FD_ses[,1]
  res[,3] <- p[,1]
  res[,4] <- FD_obs[,2]
  res[,5] <- FD_ses[,2]
  res[,6] <- p[,2]
 
  res
  
  
  
